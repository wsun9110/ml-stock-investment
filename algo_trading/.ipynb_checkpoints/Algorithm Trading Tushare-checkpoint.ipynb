{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescription-membrane",
   "metadata": {},
   "source": [
    "# Algorithm Trading Tushare\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "import tushare as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-visiting",
   "metadata": {},
   "source": [
    "## Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro = ts.pro_api('c1811742dad5bc1457bbdc81d14ef9e05c4bd17abdf9591bd730ddc5')\n",
    "# ts.set_token('c1811742dad5bc1457bbdc81d14ef9e05c4bd17abdf9591bd730ddc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "quarter = 3\n",
    "df_profit = ts.get_profit_data(year,quarter)\n",
    "df_op = ts.get_operation_data(year,quarter)\n",
    "# df_growth = ts.get_growth_data(year,quarter)\n",
    "# df_debt = ts.get_debtpaying_data(year,quarter)\n",
    "# df_cash = ts.get_cashflow_data(year,quarter)\n",
    "# df_stock = ts.get_hist_data('600848')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-identifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sitting-knowing",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only sh stocks and remove *ST stocks\n",
    "df_profit_600 = df_profit[(df_profit['code'].str.startswith('600') & (df_profit['name'].str.contains('ST') == False))]\n",
    "df_op_600 = df_op[(df_op['code'].str.startswith('600') & (df_op['name'].str.contains('ST') == False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stock code column as index and inner join two tables\n",
    "df_profit_600.set_index('code',inplace=True)\n",
    "df_op_600.set_index('code',inplace=True)\n",
    "\n",
    "# drop name column to avoid duplication when merging \n",
    "df_op_600.drop('name',axis=1,inplace=True)\n",
    "df_profit_op_600 = df_profit_600.join(df_op_600,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stock price, sh index as of Nov 30th and Sep 30th\n",
    "old_date='2021-09-30'\n",
    "new_date='2021-11-30'\n",
    "\n",
    "# get_hist_data returns a 1 line df each time, but what we need is a value\n",
    "# so we have to slice the correct column ['close'] which returns a series, then convert it to values which returns an array, and slice the first item \n",
    "# however if there is no data on that day, an empty series would be returned, and slicing the first item would throw an error, so we also need to make sure the series is not empty by checking its len\n",
    "df_profit_op_600['old_price'] = [ts.get_hist_data(i,old_date,old_date)['close'].values[0] \n",
    "                                 if len(ts.get_hist_data(i,old_date,old_date)['close']) !=0 else np.nan for i in df_profit_op_600.index]\n",
    "\n",
    "df_profit_op_600['new_price'] = [ts.get_hist_data(i,new_date,new_date)['close'].values[0] \n",
    "                                 if len(ts.get_hist_data(i,new_date,new_date)['close']) !=0 else np.nan for i in df_profit_op_600.index]\n",
    "\n",
    "\n",
    "df_profit_op_600['old_sh_index'] = ts.get_hist_data('sh',old_date,old_date)['close'].values[0]\n",
    "df_profit_op_600['new_sh_index'] = ts.get_hist_data('sh',new_date,new_date)['close'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the pct change rate for each stock and sh index\n",
    "df_profit_op_600['price_change'] = (df_profit_op_600['new_price'] - df_profit_op_600['old_price'])/df_profit_op_600['old_price']\n",
    "df_profit_op_600['index_change'] = (df_profit_op_600['new_sh_index'] - df_profit_op_600['old_sh_index'])/df_profit_op_600['old_sh_index']\n",
    "\n",
    "# compare both rates, see if a stock beats the market or not, *1 turns true/false into 1/0\n",
    "df_profit_op_600['beat'] = (df_profit_op_600['price_change'] >= df_profit_op_600['index_change']) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless features\n",
    "df_profit_op_600 = df_profit_op_600.drop(['net_profits','business_income',\n",
    "                                          'arturndays','inventory_days','currentasset_days',\n",
    "                                          'old_price','new_price','old_sh_index','new_sh_index','price_change','index_change'],axis=1)\n",
    "\n",
    "# drop rows with missing values\n",
    "df_profit_op_600.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and lables\n",
    "X = df_profit_op_600.drop(['name','beat'], axis=1)\n",
    "y = df_profit_op_600['beat']\n",
    "X = scale(X)\n",
    "\n",
    "# split data into training and testing set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-cheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "musical-affiliate",
   "metadata": {},
   "source": [
    "## Train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model svm\n",
    "# svm takes the nearest training data points (support vectors) of any class, and draw the boundary that has the largest distance to those support vectors, since in general the larger the margin the lower the generalization error of the classifier. \n",
    "# but since problems are usually not always perfectly separable with a boundary, so we allow some samples to be misclassified\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC()\n",
    "\n",
    "# train the model\n",
    "clf_svm.fit(X_train,y_train)\n",
    "\n",
    "# test the model\n",
    "clf_svm.score(X_test,y_test)\n",
    "\n",
    "# compute a 5-fold cross validation score on the whole dataset\n",
    "# it lets the model to train on a random part of the data and test it on the rest, repeat 5 times\n",
    "cross_val_score(clf_svm,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model knn\n",
    "# knn makes predictions by figuring out what are the labels of the most similar samples, and use the average of those labels as y_pred\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# train the model\n",
    "clf_knn.fit(X_train,y_train)\n",
    "\n",
    "# test the model\n",
    "clf_knn.score(X_test,y_test)\n",
    "\n",
    "cross_val_score(clf_knn,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model\n",
    "# a random forest has many decision trees (default 100 trees), each decision tree is trained and then used to predict the result, the final result is derived by taking the average of all trees' predictions(or by the majority rule)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# train the model\n",
    "clf_rf.fit(X_train,y_train)\n",
    "\n",
    "# test the model\n",
    "clf_rf.score(X_test,y_test)\n",
    "\n",
    "cross_val_score(clf_rf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-prairie",
   "metadata": {},
   "source": [
    "it is prominent that RandomForestClassifier has an overall higher accuracy (approaching 70%) than SVM and KNN. We can feed in Q4 data later when they are available to this model to predict which stocks could beat the market and construct an asset pool from which we can pick our targets and utilize our technical strategies to trade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-trout",
   "metadata": {},
   "source": [
    "## Save, load and predict\n",
    "Once we have trained our model, we want to save it so that we dont need to re-train it from scratch again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save a model\n",
    "with open('beat_clf.pkl','wb') as f:\n",
    "    pickle.dump(clf_rf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model\n",
    "with open('beat_clf.pkl','rb') as f:\n",
    "    clf_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "desirable-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profit_op_600.to_csv('df_profit_op_600_2021Q3.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-cream",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
